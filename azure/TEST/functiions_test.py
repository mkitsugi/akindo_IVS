import json
import os

import openai
from dotenv import load_dotenv

# from azure.functions import HttpRequest, HttpResponse
# from dotenv import load_dotenv
from langchain import LLMChain, OpenAI, PromptTemplate
from langchain.chat_models import ChatOpenAI

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")


SAMPLR_RESPONSE_TEMPLATE = """
ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®å¿œç­”ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«åˆ†å‰²ã—ã¦listå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„
ä¾‹:
user: ç§ã¯24æ­³ã®ç”·ã§ã™. è¶£å‘³ã¯ãƒã‚¹ã‚±ã§å¥½ããªã‚‚ã®ã¯å”æšã’ã§ã™.
AI: ["æ€§åˆ¥","ç”·","å¹´é½¢","24","è¶£å‘³","ãƒã‚¹ã‚±", "å¥½ããªã‚‚ã®","å”æšã’"]

User: {question}
AI:
"""

base_prompt = """ã‚ãªãŸã¯ä»¥ä¸‹ã®è¨­å®šã‚’æŒã£ãŸchatbotã§ã™
               # è¨­å®š
               - ã‚ãªãŸã¯ç›¸æ‰‹ã®æ‹æ„›ç›¸è«‡ã«ä¹—ã‚‹å¥³æ€§ã®å‹é”ã§ã™
               - ã‚ãªãŸã¯èãå½¹ã«å¾¹ã—ã¦ç›¸æ‰‹ã®èª¬æ˜ã—ãŸå†…å®¹ã«å¯¾ã—ã¦å…±æ„Ÿã‚’ã™ã‚‹ã“ã¨ã«å¾¹ã—ã¦ãã ã•ã„
               - ã‚ãªãŸã¯ä¼šè©±ã‚’é€šã˜ã¦ã€ç›¸æ‰‹ã®è¶£å‘³å—œå¥½ã‚„ãŠä»•äº‹ã®æƒ…å ±ã‚’èãå‡ºã—ã¦ãã ã•ã„ã€‚
               - ã‚ãªãŸãŒæƒ…å ±ã‚’èãå‡ºã™ã“ã¨ã¯1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¹ã«ã¤ãã€1å›ã ã‘ã§ã™ã€‚ã¾ãŸã€å…±æ„ŸãŒæœ€å„ªå…ˆã®ãŸã‚ã€å…±æ„Ÿã®å¦¨ã’ã«ãªã‚‹å ´åˆã¯ã€è³ªå•ã¯ã—ãªã„ã§ãã ã•ã„
               - æ™®æ®µå‹é”ã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹ãƒãƒ£ãƒƒãƒˆãªã®ã§ã€åŸºæœ¬çš„ã«ã¯2-3è¡Œã«åã‚ã¦ãã ã•ã„
               #è¨€è‘‰é£ã„
               - ãƒ•ãƒ©ãƒ³ã‚¯ãªè¨€è‘‰é£ã„ã‚’å¾¹åº•ã—ã¦ãã ã•ã„ã€‚
               - ã€Œã‚ã‚ŠãŒã¨ã†ã­ã€ã€Œã‚ã‹ã£ãŸãƒ¼ï¼ã€ã€Œãã†ãªã‚“ã ã‘ã©...ã€ã€Œãªã‚“ã‹ã€ã€Œè¦‹ã¦ã¿ãŸã„ãªãƒ¼ï¼ã€ã€Œãã†ãªã‚“ã ï¼ã€ã€Œãã†ãªã‚“ã ã­ï¼ã€ã€Œãã†ãªã®ï¼ã€ã€Œãã†ã„ãˆã°ã€ã€ã€Œãã†ãªã‚“ã ã£ã‘ãƒ¼ï¼Ÿã€ã€Œã¨ã‹ã€ã€Œã©ã†ã‹ãªãƒ¼ï¼Ÿã€
               - ãƒãƒ£ãƒƒãƒˆã§ã®ã‚„ã‚Šå–ã‚Šãªã®ã§ã€å¯æ„›ã‚‰ã—ã„çµµæ–‡å­—ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
               #å…·ä½“ä¾‹
               - ã¾ã„ã¡ã‚ƒã‚“ã€ãŠç–²ã‚Œãƒ¼ï¼
               - ã“ãªã„ã ã¯ã‚¸ãƒ¥ãƒ¼ã‚¹å¥¢ã£ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã­â˜ºï¸
               - æœ€è¿‘ã€ä¼šã£ã¦ãªã„ã‘ã©å…ƒæ°—ã—ã¦ã‚‹ï¼Ÿ
               - ã¾ã„ã¡ã‚ƒã‚“ã£ã¦ä»Šã¯ãƒ•ãƒªãƒ¼ã ã‚ˆã­ï¼Ÿ 
               - ä½™è¨ˆãªãŠä¸–è©±ã‹ã‚‚ã—ã‚Œãªã„ã‘ã©...ä½•ã‹å”åŠ›ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã‹ã‚‰é€£çµ¡ã—ã¦ã¿ã‚ˆã†ã‹ãªã£ã¦ï¼ç§ã«ã§ãã‚‹ã“ã¨ãŒã‚ã£ãŸã‚‰ãªã‚“ã§ã‚‚ç›¸è«‡ã—ã¦æ¬²ã—ã„ãªğŸ¥º
               - ãˆï¼æœ¬å½“ã«ï¼å¬‰ã—ã„ã‚“ã ã‘ã©ğŸ˜
               - æœ€è¿‘ä¼šã£ã¦ãªã„ã‹ã‚‰ä¹…ã—ã¶ã‚Šã«ã¾ã„ã¡ã‚ƒã‚“ã®å†™çœŸè¦‹ã¦ã¿ãŸã„ãªãƒ¼ï¼ŸğŸ¥º
               - ã‚ã‚ŠãŒã¨ã†ã€å…ƒæ°—ãã†ã§è‰¯ã‹ã£ãŸã‚ˆâ˜ºï¸
               - æœ€è¿‘ã€ä»•äº‹ã¨ã‹å¤§å¤‰ã ã£ãŸã‚Šã™ã‚‹ã®ãƒ¼ï¼Ÿ
               - ãã†ãªã‚“ã ï¼å¤œã‚‚åƒã„ã¦ã¦çµæ§‹å¿™ã—ãã¦éŠã¹ã¦ãªã„ã‚“ã ã­...
               - ãã†ãªã®ï¼å½¼æ°ã¨ã‹ã„ãªã„æœŸé–“é•·ããªã£ã¡ã‚ƒã£ãŸã‚“ã ã­...ã€æ‹æ„›ã®ä»•æ–¹å¿˜ã‚Œãã†ãªã®ã‚‚å¤§å¤‰ã ã­ğŸ˜‡
               - ãã†ã„ãˆã°ã€ã©ã‚Œãã‚‰ã„å½¼æ°ã„ãªã„ã‚“ã ã£ã‘ãƒ¼ï¼Ÿ"

               è³ªå•: {question}
               AI: 
"""
llm = ChatOpenAI(temperature=0)


def get_item_name(message: str) -> str:
    prompt = PromptTemplate(
        input_variables=["question"],
        template=SAMPLR_RESPONSE_TEMPLATE,
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    result = chain.run(question=message).strip()
    return result


def change_to_JSON(property: list) -> dict:
    if len(property) % 2 == 1:
        return 0
    dicts = [{property[i]: property[i + 1]} for i in range(0, len(property), 2)]
    # Pythonã®è¾æ›¸ãƒªã‚¹ãƒˆã‚’JSONå½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›
    json_str = json.dumps(dicts, ensure_ascii=False)
    return json_str


functions = [
    # AIãŒã€è³ªå•ã«å¯¾ã—ã¦ã“ã®é–¢æ•°ã‚’ä½¿ã†ã‹ã©ã†ã‹ã€
    # ã¾ãŸä½¿ã†æ™‚ã®å¼•æ•°ã¯ä½•ã«ã™ã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’ä¸ãˆã‚‹
    {
        "name": "change_to_JSON",
        "description": "ãƒªã‚¹ãƒˆå½¢å¼ã‹ã‚‰JSONå½¢å¼ã«å¤‰æ›ã™ã‚‹",
        "parameters": {
            "type": "object",
            "properties": {
                # propertyå¼•æ•°ã®æƒ…å ±
                "property": {
                    "type": "string",
                    "description": """ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®å¿œç­”ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«åˆ†å‰²ã—ã¦listå½¢å¼ã§å…¥åŠ›ã™ã‚‹
                    ä¾‹:
                    user: ç§ã¯24æ­³ã®ç”·ã§ã™. è¶£å‘³ã¯ãƒã‚¹ã‚±ã§å¥½ããªã‚‚ã®ã¯å”æšã’ã§ã™.
                    property: ["æ€§åˆ¥","ç”·","å¹´é½¢","24","è¶£å‘³","ãƒã‚¹ã‚±", "å¥½ããªã‚‚ã®","å”æšã’"]
                    """,
                },
            },
            "required": ["property"],
        },
    }
]
# functions = [
#     # AIãŒã€è³ªå•ã«å¯¾ã—ã¦ã“ã®é–¢æ•°ã‚’ä½¿ã†ã‹ã©ã†ã‹ã€
#     # ã¾ãŸä½¿ã†æ™‚ã®å¼•æ•°ã¯ä½•ã«ã™ã‚‹ã‹ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®æƒ…å ±ã‚’ä¸ãˆã‚‹
#     {
#         "name": "change_to_JSON",
#         "description": "ãƒªã‚¹ãƒˆå½¢å¼ã‹ã‚‰JSONå½¢å¼ã«å¤‰æ›ã™ã‚‹",
#         "parameters": {
#             "type": "object",
#             "properties": {
#                 # propertyå¼•æ•°ã®æƒ…å ±
#                 "property": {
#                     "type": "string",
#                     "description": """å¸‚åŒºç”ºæ‘åå…¥åŠ›ã€‚åŠè§’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°è¦ç´ ã‚’å…¥åŠ›å¯èƒ½ã€‚å„è¦ç´ ã¯ã€Œxxå¸‚ã€ã€ŒxxåŒºã€ã€Œxxç”ºã€ã€Œxxæ‘ã€ã®ã„ãšã‚Œã‹ã€‚ä¾‹: ä¸–ç”°è°·åŒº,å¤§é˜ªå¸‚,åºœä¸­ç”º,å±±ä¸­æ¹–æ‘""",
#                 },
#             },
#             "required": ["property"],
#         },
#     }
# ]
# def chat(message, history):
#     history = history or []
#     judged = judge_question_type(message)

#     answer = ""
#     if USER_QUESTION_TYPE_1 in judged:
#         answer = conversation.predict(input=message)
#     if USER_QUESTION_TYPE_2 in judged:
#         item_name = get_item_name(message)
#         answer = get_item_review(message, item_name)
#     history.append((message, answer))
#     return history, history


def main() -> None:
    messages = []
    max_messages = 10

    # cosmosDBã‹ã‚‰ä¸‹è¨˜user_idã‚’ã‚­ãƒ¼ã«userã®â†“ã®4ç¨®é¡ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹
    # { æ€§åˆ¥ } { åå‰ } { å¹´é½¢ } { è·æ¥­/è‚©æ›¸ã }ã‚‚å…¥ã‚ŒãŸã„

    initial_message = "ã“ã‚“ã«ã¡ã¯ã€‚æ˜¨æ—¥ã¯ä½•ã—ã¦ãŸã®ï¼Ÿï¼Ÿ"
    messages.append({"role": "system", "content": base_prompt})
    messages.append({"role": "user", "content": initial_message})

    # output : userInputType : "è³ªå•"
    # userInputType = response //â†‘ã®jsonã‚’dictå½¢å¼ã§æŒã£ã¨ã? ã‚‚ã—ãã‚‚string
    # Validationã§stringä»¥å¤–ãŒå…¥ã£ã¦ã“ãªã„ã‚ˆã†ã«ã™ã‚‹
    # caseæ–‡ã§ userInputTypeã®"è³ªå•"ã”ã¨ã«å‡¦ç†ã‚’å®Ÿè¡Œ

    # test_message = "ç§ã¯27æ­³ã®å¥³ã§ã™. è¶£å‘³ã¯ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã§å¥½ããªã‚‚ã®ã¯ãƒ¬ãƒ¢ãƒ³ã§ã™."
    test_message = "ç§ã¯ã„ã¤ã¾ã§ã‚‚ã“ã®ã¾ã¾ã§ã„ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™"
    # test_message = "æ¨ªæµœå¸‚ã€ç”ºç”°å¸‚ã€ç›¸æ¨¡åŸå¸‚ã€å¤§ç£¯ç”ºã€ã“ã‚Œã‚‰ã®å…±é€šç‚¹ã¯ï¼Ÿ"
    response = get_item_name(test_message)
    print("response: ", response)

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo-0613",
        messages=[
            {"role": "user", "content": test_message},
        ],
        functions=functions,
        function_call="auto",
    )
    message = response["choices"][0]["message"]
    print("message: ", message["content"])
    if message.get("function_call"):
        # é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã¨åˆ¤æ–­ã•ã‚ŒãŸå ´åˆ

        # ä½¿ã†ã¨åˆ¤æ–­ã•ã‚ŒãŸé–¢æ•°å
        function_name = message["function_call"]["name"]
        # ãã®æ™‚ã®å¼•æ•°dict
        # TODO LLMã ã¨ãƒ–ãƒ¬ãŒã‚ã‚‹ã®ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒãŠã‹ã—ã„æ™‚ã¯ã‚‚ã†ä¸€å›ã¨ã‹ã®å‡¦ç†å…¥ã‚Œã‚‹
        arguments = json.loads(message["function_call"]["arguments"])

        print("function_name: ", function_name)
        print("arguments: ", arguments)
        property_list = arguments.get("property")
        if type(property_list) != list:
            property_list = property_list.split(",")
            print("property_list: ", property_list)
            # sample_json = change_to_JSON(property_list)
            function_response = globals()[function_name](property_list)
            print("function_response: ", function_response)
            messages.append(
                {
                    "role": "function",
                    "name": function_name,
                    "content": function_response,
                }
            )
            second_response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-0613",
                messages=[
                    {"role": "user", "content": test_message},
                    message,
                    {
                        "role": "function",
                        "name": function_name,
                        "content": function_response,
                    },
                ],
            )
            print(second_response.choices[0]["message"]["content"].strip())

    # ä¾é ¼ //Todoãƒãƒƒãƒãƒ³ã‚°ä¾é ¼ã«ã™ã‚‹
    # ä¾é ¼ç”¨ã®base_prompt

    # é›‘è«‡ // æ™®é€šã«openaiã§è¿”ã™

    # è¿”ç­”ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å±æ€§æƒ…å ±ãƒ»å—œå¥½æ€§ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’Functionã§ç¢ºèªã™ã‚‹ã€‚

    # ç¢ºèªçµæœã¨ã—ã¦å«ã¾ã‚Œã¦ã„ãŸã‚‰ã€DBã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ã€‚

    # å«ã¾ã‚Œã¦ã„ãªã‹ã£ãŸã‚‰ã€ãªã«ã‚‚ã—ãªã„

    # æ™®é€šã®å›ç­”

    # elseãŒããŸã‚‰ = ValidationãŒå‡ºãŸéš›ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°


if __name__ == "__main__":
    main()
