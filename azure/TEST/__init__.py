import os
import openai
import json
from azure.functions import HttpRequest, HttpResponse
from azure.cosmos import CosmosClient
from langchain.memory import ConversationBufferMemory, ChatMessageHistory, ConversationEntityMemory
from langchain.schema import HumanMessage, AIMessage
from langchain.chains import ConversationChain
from langchain import LLMChain, PromptTemplate
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv

# APIã‚­ãƒ¼ã®å–å¾—
load_dotenv()
OPENAI_KEY = os.environ.get('OPENAI_API_KEY')
openai.api_key = OPENAI_KEY

# Cosmos DBæ¥ç¶šè¨­å®š
COSMOS_DB_CONNECTION_STR = os.environ.get('COSMOS_DB_CONNECTION_STR')
DATABASE_NAME = "KG_AK"
CONTAINER_NAME = "Chats"
client = CosmosClient.from_connection_string(COSMOS_DB_CONNECTION_STR)
database = client.get_database_client(DATABASE_NAME)
container = database.get_container_client(CONTAINER_NAME)

#llmãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
llm = ChatOpenAI(temperature=0.3,model="gpt-3.5-turbo-16k-0613")

#åˆ†é¡å‡¦ç†
##ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
ASK_QUESTION_TYPE_TEMPLATE = """
    ###æŒ‡ä»¤###_
    ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒãƒ£ãƒƒãƒˆç›¸æ‰‹ã¨ã—ã¦ã€è¿”ç­”ã—ã¾ã™ã€‚
    ã¾ãŸã€ã‚ãªãŸã¯ä¼šè©±ã‚’é€šã˜ã¦ã€ç›¸æ‰‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ç›¸æ‰‹ã«é–¢ã™ã‚‹å…·ä½“çš„ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
    ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã‚’ã—ã¦ãã ã•ã„ã€‚

    jsonãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
    ```
    "UserInputType" : "æƒ…å ±é‡ã‚ã‚Š" or "æƒ…å ±é‡ãªã—"
    ```

    #è³ªå•: {userinput}

    #å‡ºåŠ›:
    """

##åˆ†é¡å‡¦ç†
def judge_conversation_type(userinput: str) -> str:

    prompt = PromptTemplate(
        input_variables=["userinput"],
        template=ASK_QUESTION_TYPE_TEMPLATE,
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(userinput=userinput).strip()

#CosmosDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
def get_Chats_from_cosmos(chatroomid: str) -> list:
    query = f"SELECT * FROM c WHERE c.chat_room_id = '{chatroomid}'"
    Chats = list(container.query_items(
        query=query,
        enable_cross_partition_query=True
    ))    
    return Chats


##ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
SUMMARY_QUESTION_TYPE_TEMPLATE="""
ã‚ãªãŸã¯ã‚ãªãŸãŒæŒã£ã¦ã„ã‚‹æƒ…å ±ã‚’é©åˆ‡ã«è¦ç´„ã—ã¦ç›¸æ‰‹ã«èª¬æ˜ã™ã‚‹ã®ãŒéå¸¸ã«ã†ã¾ã„ã¨æ€ã‚ã‚Œã¦ã„ã‚‹äººé–“ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å¿œç­”ã«å¯¾ã—ã¦é©åˆ‡ã«è¿”ã—ã¦ãã ã•ã„

#å¿œç­”: 

#å‡ºåŠ›: 

"""

base_prompt = """ã‚ãªãŸã¯ä»¥ä¸‹ã®è¨­å®šã‚’æŒã£ãŸchatbotã§ã™\
               # è¨­å®š\
               - ã‚ãªãŸã¯ç›¸æ‰‹ã®æ‹æ„›ç›¸è«‡ã«ä¹—ã‚‹å¥³æ€§ã®å‹é”ã§ã™\
               - ã‚ãªãŸã¯èãå½¹ã«å¾¹ã—ã¦ç›¸æ‰‹ã®èª¬æ˜ã—ãŸå†…å®¹ã«å¯¾ã—ã¦å…±æ„Ÿã‚’ã™ã‚‹ã“ã¨ã«å¾¹ã—ã¦ãã ã•ã„\
               - ã‚ãªãŸã¯ä¼šè©±ã‚’é€šã˜ã¦ã€ç›¸æ‰‹ã®è¶£å‘³å—œå¥½ã‚„ãŠä»•äº‹ã®æƒ…å ±ã‚’èãå‡ºã—ã¦ãã ã•ã„ã€‚\
               - ã‚ãªãŸãŒæƒ…å ±ã‚’èãå‡ºã™ã“ã¨ã¯1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¹ã«ã¤ãã€1å›ã ã‘ã§ã™ã€‚ã¾ãŸã€å…±æ„ŸãŒæœ€å„ªå…ˆã®ãŸã‚ã€å…±æ„Ÿã®å¦¨ã’ã«ãªã‚‹å ´åˆã¯ã€è³ªå•ã¯ã—ãªã„ã§ãã ã•ã„\
               - æ™®æ®µå‹é”ã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹ãƒãƒ£ãƒƒãƒˆãªã®ã§ã€åŸºæœ¬çš„ã«ã¯2-3è¡Œã«åã‚ã¦ãã ã•ã„\
               #è¨€è‘‰é£ã„\
               - ãƒ•ãƒ©ãƒ³ã‚¯ãªè¨€è‘‰é£ã„ã‚’å¾¹åº•ã—ã¦ãã ã•ã„ã€‚\
               - ã€Œã‚ã‚ŠãŒã¨ã†ã­ã€ã€Œã‚ã‹ã£ãŸãƒ¼ï¼ã€ã€Œãã†ãªã‚“ã ã‘ã©...ã€ã€Œãªã‚“ã‹ã€ã€Œè¦‹ã¦ã¿ãŸã„ãªãƒ¼ï¼ã€ã€Œãã†ãªã‚“ã ï¼ã€ã€Œãã†ãªã‚“ã ã­ï¼ã€ã€Œãã†ãªã®ï¼ã€ã€Œãã†ã„ãˆã°ã€ã€ã€Œãã†ãªã‚“ã ã£ã‘ãƒ¼ï¼Ÿã€ã€Œã¨ã‹ã€ã€Œã©ã†ã‹ãªãƒ¼ï¼Ÿã€\
               - ãƒãƒ£ãƒƒãƒˆã§ã®ã‚„ã‚Šå–ã‚Šãªã®ã§ã€å¯æ„›ã‚‰ã—ã„çµµæ–‡å­—ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚\
               #å…·ä½“ä¾‹\
               - ""åå‰ãŒå…¥ã‚Šã¾ã™"" ã¡ã‚ƒã‚“ã€ãŠç–²ã‚Œãƒ¼ï¼\
               - ã“ãªã„ã ã¯ã‚¸ãƒ¥ãƒ¼ã‚¹å¥¢ã£ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã­â˜ºï¸\
               - æœ€è¿‘ã€ä¼šã£ã¦ãªã„ã‘ã©å…ƒæ°—ã—ã¦ã‚‹ï¼Ÿ\
               - ""åå‰ãŒå…¥ã‚Šã¾ã™""ã£ã¦ä»Šã¯ãƒ•ãƒªãƒ¼ã ã‚ˆã­ï¼Ÿ \
               - ä½™è¨ˆãªãŠä¸–è©±ã‹ã‚‚ã—ã‚Œãªã„ã‘ã©...ä½•ã‹å”åŠ›ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã‹ã‚‰é€£çµ¡ã—ã¦ã¿ã‚ˆã†ã‹ãªã£ã¦ï¼ç§ã«ã§ãã‚‹ã“ã¨ãŒã‚ã£ãŸã‚‰ãªã‚“ã§ã‚‚ç›¸è«‡ã—ã¦æ¬²ã—ã„ãªğŸ¥º\
               - ãˆï¼æœ¬å½“ã«ï¼å¬‰ã—ã„ã‚“ã ã‘ã©ğŸ˜\
               - æœ€è¿‘ä¼šã£ã¦ãªã„ã‹ã‚‰ä¹…ã—ã¶ã‚Šã«""åå‰ãŒå…¥ã‚Šã¾ã™""ã®å†™çœŸè¦‹ã¦ã¿ãŸã„ãªãƒ¼ï¼ŸğŸ¥º\
               - ã‚ã‚ŠãŒã¨ã†ã€å…ƒæ°—ãã†ã§è‰¯ã‹ã£ãŸã‚ˆâ˜ºï¸\
               - æœ€è¿‘ã€ä»•äº‹ã¨ã‹å¤§å¤‰ã ã£ãŸã‚Šã™ã‚‹ã®ãƒ¼ï¼Ÿ\
               - ãã†ãªã‚“ã ï¼å¤œã‚‚åƒã„ã¦ã¦çµæ§‹å¿™ã—ãã¦éŠã¹ã¦ãªã„ã‚“ã ã­...\
               - ãã†ãªã®ï¼å½¼æ°ã¨ã‹ã„ãªã„æœŸé–“é•·ããªã£ã¡ã‚ƒã£ãŸã‚“ã ã­...ã€æ‹æ„›ã®ä»•æ–¹å¿˜ã‚Œãã†ãªã®ã‚‚å¤§å¤‰ã ã­ğŸ˜‡\
               - ãã†ã„ãˆã°ã€ã©ã‚Œãã‚‰ã„å½¼æ°ã„ãªã„ã‚“ã ã£ã‘ãƒ¼ï¼Ÿ
               

               #ä¼šè©±å±¥æ­´: {history}

               #å…¥åŠ›: {input}

               #å‡ºåŠ›: 

               """

#Chatsã‚’ãƒ¡ãƒ¢ãƒªãƒ¼åŒ–ã—ã¦ã€å‡ºåŠ›
def output_from_memory(Chats: list, initial_message: str):
    # Initialize memory
    memory = ConversationBufferMemory(return_messages=True)
    # memory = ConversationEntityMemory(llm=llm)

    # Load messages into memory
    for chat in Chats:
        message = HumanMessage(content=chat['message']) if chat['user_id'] != 'AI' else AIMessage(content=chat['message'])

        # Add the message to the memory
        if isinstance(message, HumanMessage):
            memory.chat_memory.add_user_message(message.content)
        else:
            memory.chat_memory.add_ai_message(message.content)

    prompt = PromptTemplate(template=base_prompt,input_variables=["history","input"]) 

    chain = ConversationChain(llm=llm, verbose=True, memory=memory,prompt=prompt)
    summary = chain.predict(input=initial_message)

    return summary


def main(req: HttpRequest) -> HttpResponse:

    initial_message = req.params.get('message')
    # user_id = req.params.get('user_id')  # user_idã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã‹ã‚‰å–å¾—
    chatroomid = req.params.get('roomId')  # chatroomidã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã‹ã‚‰å–å¾—

    if not initial_message:
        try:
            req_body = req.get_json()
        except ValueError:
            pass
        else:
            initial_message = req_body.get('message') #ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã‹ã‚‰å–å¾—
            # user_id = req_body.get('user_id')  # user_idã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã‹ã‚‰å–å¾—
            chatroomid = req_body.get('roomId')  # chatroomidã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã‹ã‚‰å–å¾—
 
    if initial_message:
        # messages.append({"role": "user", "content": initial_message})
        response = judge_conversation_type(userinput=initial_message)
        # response = openai.ChatCompletion.create(model="gpt-3.5-turbo-16k-0613", messages=messages)
        # ai_response = response["choices"][0]["message"]["content"]
        chatsoutput = get_Chats_from_cosmos(chatroomid=chatroomid)
        output = output_from_memory(Chats=chatsoutput,initial_message=initial_message)
        # response_body = json.dumps({"chats": [chat["message"] for chat in chatsoutput], "summary" : output}, ensure_ascii=False, indent=4)
        # response_body = json.dumps({"chats": chatsoutput, "summary" : output}, ensure_ascii=False, indent=4)
        # return HttpResponse(response_body)
        return HttpResponse(output)
    else:
        return HttpResponse("Please pass a message on the query string or in the request body", status_code=400)
