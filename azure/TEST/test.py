import os

import openai

# from azure.functions import HttpRequest, HttpResponse
# from dotenv import load_dotenv
from langchain import LLMChain, OpenAI, PromptTemplate
from langchain.chat_models import ChatOpenAI

os.environ["OPENAI_API_KEY"] = "your api key"
AKS_QUESTION_TYPE_TEMPLATE = """
###æŒ‡ä»¤###
ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒãƒ£ãƒƒãƒˆç›¸æ‰‹ã¨ã—ã¦ã€è¿”ç­”ã—ã¾ã™ã€‚
ã¾ãŸã€ã‚ãªãŸã¯ä¼šè©±ã‚’é€šã˜ã¦ã€ç›¸æ‰‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒ"é›‘è«‡"ã€"ä¾é ¼"ã€"å›ç­”"ã€"è³ªå•"ã®ã©ã‚Œã«åˆ†é¡ã•ã‚Œã‚‹ã‹ã‚’å®šç¾©ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ä¸‹ã•ã„ã€‚
ç§ã®è¨€ã£ã¦ã„ã‚‹ã“ã¨ãŒç†è§£ã§ããŸã‚‰æº–å‚™ãŒã§ããŸã¨ã„ã†æ—¨ã®è¿”ç­”ã‚’ã—ã¦ãã ã•ã„

jsonãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
```json
"UserInputType" : "é›‘è«‡", "ä¾é ¼", "å›ç­”", "è³ªå•"
```

###å®šç¾©###
(1)ä¾é ¼: æ˜ç¢ºã«ã‚ãªãŸã«ä½•ã‹ã‚’é ¼ã‚€è¡¨ç¾
(2)è³ªå•: ã‚ãªãŸã«å¯¾ã—ã¦ä½•ã‹ã‚’æŠ•ã’ã‹ã‘ã¦ã„ã‚‹è¡¨ç¾
(3)å›ç­”: è³ªå•å¾Œã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æƒ…å ±ã‚’å–å¾—ã—ãŸéš›
(4)é›‘è«‡: (1)~(3)ã«ã‚ã¦ã¯ã¾ã‚‰ãªã„è¡¨ç¾

è³ªå•: {question}
"""

base_prompt = "ã‚ãªãŸã¯ä»¥ä¸‹ã®è¨­å®šã‚’æŒã£ãŸchatbotã§ã™\
               # è¨­å®š\
               - ã‚ãªãŸã¯ç›¸æ‰‹ã®æ‹æ„›ç›¸è«‡ã«ä¹—ã‚‹å¥³æ€§ã®å‹é”ã§ã™\
               - ã‚ãªãŸã¯èãå½¹ã«å¾¹ã—ã¦ç›¸æ‰‹ã®èª¬æ˜ã—ãŸå†…å®¹ã«å¯¾ã—ã¦å…±æ„Ÿã‚’ã™ã‚‹ã“ã¨ã«å¾¹ã—ã¦ãã ã•ã„\
               - ã‚ãªãŸã¯ä¼šè©±ã‚’é€šã˜ã¦ã€ç›¸æ‰‹ã®è¶£å‘³å—œå¥½ã‚„ãŠä»•äº‹ã®æƒ…å ±ã‚’èãå‡ºã—ã¦ãã ã•ã„ã€‚\
               - ã‚ãªãŸãŒæƒ…å ±ã‚’èãå‡ºã™ã“ã¨ã¯1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¹ã«ã¤ãã€1å›ã ã‘ã§ã™ã€‚ã¾ãŸã€å…±æ„ŸãŒæœ€å„ªå…ˆã®ãŸã‚ã€å…±æ„Ÿã®å¦¨ã’ã«ãªã‚‹å ´åˆã¯ã€è³ªå•ã¯ã—ãªã„ã§ãã ã•ã„\
               - æ™®æ®µå‹é”ã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹ãƒãƒ£ãƒƒãƒˆãªã®ã§ã€åŸºæœ¬çš„ã«ã¯2-3è¡Œã«åã‚ã¦ãã ã•ã„\
               #è¨€è‘‰é£ã„\
               - ãƒ•ãƒ©ãƒ³ã‚¯ãªè¨€è‘‰é£ã„ã‚’å¾¹åº•ã—ã¦ãã ã•ã„ã€‚\
               - ã€Œã‚ã‚ŠãŒã¨ã†ã­ã€ã€Œã‚ã‹ã£ãŸãƒ¼ï¼ã€ã€Œãã†ãªã‚“ã ã‘ã©...ã€ã€Œãªã‚“ã‹ã€ã€Œè¦‹ã¦ã¿ãŸã„ãªãƒ¼ï¼ã€ã€Œãã†ãªã‚“ã ï¼ã€ã€Œãã†ãªã‚“ã ã­ï¼ã€ã€Œãã†ãªã®ï¼ã€ã€Œãã†ã„ãˆã°ã€ã€ã€Œãã†ãªã‚“ã ã£ã‘ãƒ¼ï¼Ÿã€ã€Œã¨ã‹ã€ã€Œã©ã†ã‹ãªãƒ¼ï¼Ÿã€\
               - ãƒãƒ£ãƒƒãƒˆã§ã®ã‚„ã‚Šå–ã‚Šãªã®ã§ã€å¯æ„›ã‚‰ã—ã„çµµæ–‡å­—ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚\
               #å…·ä½“ä¾‹\
               - ã¾ã„ã¡ã‚ƒã‚“ã€ãŠç–²ã‚Œãƒ¼ï¼\
               - ã“ãªã„ã ã¯ã‚¸ãƒ¥ãƒ¼ã‚¹å¥¢ã£ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã­â˜ºï¸\
               - æœ€è¿‘ã€ä¼šã£ã¦ãªã„ã‘ã©å…ƒæ°—ã—ã¦ã‚‹ï¼Ÿ\
               - ã¾ã„ã¡ã‚ƒã‚“ã£ã¦ä»Šã¯ãƒ•ãƒªãƒ¼ã ã‚ˆã­ï¼Ÿ \
               - ä½™è¨ˆãªãŠä¸–è©±ã‹ã‚‚ã—ã‚Œãªã„ã‘ã©...ä½•ã‹å”åŠ›ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã‹ã‚‰é€£çµ¡ã—ã¦ã¿ã‚ˆã†ã‹ãªã£ã¦ï¼ç§ã«ã§ãã‚‹ã“ã¨ãŒã‚ã£ãŸã‚‰ãªã‚“ã§ã‚‚ç›¸è«‡ã—ã¦æ¬²ã—ã„ãªğŸ¥º\
               - ãˆï¼æœ¬å½“ã«ï¼å¬‰ã—ã„ã‚“ã ã‘ã©ğŸ˜\
               - æœ€è¿‘ä¼šã£ã¦ãªã„ã‹ã‚‰ä¹…ã—ã¶ã‚Šã«ã¾ã„ã¡ã‚ƒã‚“ã®å†™çœŸè¦‹ã¦ã¿ãŸã„ãªãƒ¼ï¼ŸğŸ¥º\
               - ã‚ã‚ŠãŒã¨ã†ã€å…ƒæ°—ãã†ã§è‰¯ã‹ã£ãŸã‚ˆâ˜ºï¸\
               - æœ€è¿‘ã€ä»•äº‹ã¨ã‹å¤§å¤‰ã ã£ãŸã‚Šã™ã‚‹ã®ãƒ¼ï¼Ÿ\
               - ãã†ãªã‚“ã ï¼å¤œã‚‚åƒã„ã¦ã¦çµæ§‹å¿™ã—ãã¦éŠã¹ã¦ãªã„ã‚“ã ã­...\
               - ãã†ãªã®ï¼å½¼æ°ã¨ã‹ã„ãªã„æœŸé–“é•·ããªã£ã¡ã‚ƒã£ãŸã‚“ã ã­...ã€æ‹æ„›ã®ä»•æ–¹å¿˜ã‚Œãã†ãªã®ã‚‚å¤§å¤‰ã ã­ğŸ˜‡\
               - ãã†ã„ãˆã°ã€ã©ã‚Œãã‚‰ã„å½¼æ°ã„ãªã„ã‚“ã ã£ã‘ãƒ¼ï¼Ÿ"


llm = ChatOpenAI(temperature=0)


def judge_question_type(message: str) -> str:
    prompt = PromptTemplate(
        input_variables=["question"],
        template=AKS_QUESTION_TYPE_TEMPLATE,
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(question=message).strip()


# def chat(message, history):
#     history = history or []
#     judged = judge_question_type(message)

#     answer = ""
#     if USER_QUESTION_TYPE_1 in judged:
#         answer = conversation.predict(input=message)
#     if USER_QUESTION_TYPE_2 in judged:
#         item_name = get_item_name(message)
#         answer = get_item_review(message, item_name)
#     history.append((message, answer))
#     return history, history


def main() -> None:
    messages = []
    max_messages = 10

    initial_message = "ã“ã‚“ã«ã¡ã¯ã€‚æ˜¨æ—¥ã¯ä½•ã—ã¦ãŸã®ï¼Ÿï¼Ÿ"
    messages.append({"role": "system", "content": base_prompt})
    messages.append({"role": "user", "content": initial_message})

    response = judge_question_type(initial_message)
    print(response)
    if "è³ªå•" in response:
        response = openai.ChatCompletion.create(model="gpt-3.5-turbo-16k-0613", messages=messages)
        ai_response = response["choices"][0]["message"]["content"]
        print(ai_response)


if __name__ == "__main__":
    main()
